{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 42.3M  100 42.3M    0     0  46.9M      0 --:--:-- --:--:-- --:--:-- 58.3M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./parking-space-detection-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/trainingdatapro/parking-space-detection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  parking-space-detection-dataset.zip\n",
      "  inflating: parking-space-detection-dataset/annotations.xml  \n",
      "  inflating: parking-space-detection-dataset/boxes/0.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/1.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/10.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/11.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/12.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/13.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/14.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/15.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/17.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/18.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/19.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/2.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/20.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/21.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/22.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/24.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/25.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/26.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/27.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/28.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/29.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/3.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/30.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/31.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/32.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/4.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/5.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/6.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/8.png  \n",
      "  inflating: parking-space-detection-dataset/boxes/9.png  \n",
      "  inflating: parking-space-detection-dataset/images/0.png  \n",
      "  inflating: parking-space-detection-dataset/images/1.png  \n",
      "  inflating: parking-space-detection-dataset/images/10.png  \n",
      "  inflating: parking-space-detection-dataset/images/11.png  \n",
      "  inflating: parking-space-detection-dataset/images/12.png  \n",
      "  inflating: parking-space-detection-dataset/images/13.png  \n",
      "  inflating: parking-space-detection-dataset/images/14.png  \n",
      "  inflating: parking-space-detection-dataset/images/15.png  \n",
      "  inflating: parking-space-detection-dataset/images/17.png  \n",
      "  inflating: parking-space-detection-dataset/images/18.png  \n",
      "  inflating: parking-space-detection-dataset/images/19.png  \n",
      "  inflating: parking-space-detection-dataset/images/2.png  \n",
      "  inflating: parking-space-detection-dataset/images/20.png  \n",
      "  inflating: parking-space-detection-dataset/images/21.png  \n",
      "  inflating: parking-space-detection-dataset/images/22.png  \n",
      "  inflating: parking-space-detection-dataset/images/24.png  \n",
      "  inflating: parking-space-detection-dataset/images/25.png  \n",
      "  inflating: parking-space-detection-dataset/images/26.png  \n",
      "  inflating: parking-space-detection-dataset/images/27.png  \n",
      "  inflating: parking-space-detection-dataset/images/28.png  \n",
      "  inflating: parking-space-detection-dataset/images/29.png  \n",
      "  inflating: parking-space-detection-dataset/images/3.png  \n",
      "  inflating: parking-space-detection-dataset/images/30.png  \n",
      "  inflating: parking-space-detection-dataset/images/31.png  \n",
      "  inflating: parking-space-detection-dataset/images/32.png  \n",
      "  inflating: parking-space-detection-dataset/images/4.png  \n",
      "  inflating: parking-space-detection-dataset/images/5.png  \n",
      "  inflating: parking-space-detection-dataset/images/6.png  \n",
      "  inflating: parking-space-detection-dataset/images/8.png  \n",
      "  inflating: parking-space-detection-dataset/images/9.png  \n",
      "  inflating: parking-space-detection-dataset/parking.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip parking-space-detection-dataset.zip -d parking-space-detection-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('parking-space-detection-dataset')\n",
    "root = ET.parse(dataset_path / 'annotations.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for image_tag in root.findall('image'):\n",
    "    image_name = image_tag.get('name')\n",
    "    image_width = int(image_tag.get('width'))\n",
    "    image_height = int(image_tag.get('height'))\n",
    "\n",
    "    polygons = []\n",
    "    for polygon_tag in image_tag.findall('polygon'):\n",
    "        polygon_label = polygon_tag.get('label')\n",
    "        polygon_points = polygon_tag.get('points')\n",
    "        polygons.append((polygon_label, polygon_points))\n",
    "\n",
    "    imgs.append((image_name, polygons, (image_width, image_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set()\n",
    "\n",
    "for img in imgs:\n",
    "    for polygon in img[1]:\n",
    "        classes.add(polygon[0])\n",
    "\n",
    "classes = list(classes)\n",
    "class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# replace the label with the index\n",
    "imgs = [(img[0], [(class_to_idx[polygon[0]], polygon[1]) for polygon in img[1]], img[2]) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SPLIT  1\n",
      "RUNNING SPLIT  2\n",
      "RUNNING SPLIT  3\n",
      "RUNNING SPLIT  4\n"
     ]
    }
   ],
   "source": [
    "ksplit = 4\n",
    "kf = KFold(n_splits=ksplit, shuffle=True, random_state=42)\n",
    "kfolds = list(kf.split(imgs))\n",
    "\n",
    "folds = [f\"split_{n}\" for n in range(1, ksplit + 1)]\n",
    "\n",
    "save_path = Path(dataset_path / f\"{ksplit}-Fold_Cross-val\")\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ds_yamls = []\n",
    "\n",
    "for n, (train_idx, val_idx) in enumerate(kfolds):\n",
    "    print(\"RUNNING SPLIT \", n + 1)\n",
    "    train_data = [imgs[i] for i in train_idx]\n",
    "    val_data = [imgs[i] for i in val_idx]\n",
    "\n",
    "    split_dir = save_path / folds[n]\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"train\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"train\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"val\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"val\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dataset_yaml = split_dir / f\"dataset.yaml\"\n",
    "    ds_yamls.append(dataset_yaml)\n",
    "\n",
    "    with open(dataset_yaml, \"w\") as ds_y:\n",
    "\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                \"path\": split_dir.resolve().as_posix(),\n",
    "                \"train\": \"./train\",\n",
    "                \"val\": \"./val\",\n",
    "                \"names\": idx_to_class,\n",
    "            },\n",
    "            ds_y,\n",
    "        )\n",
    "\n",
    "    #for image_data, split in zip([train_data, val_data], [\"train\", \"val\"]):\n",
    "    for image_data, split in zip([train_data, val_data], [\"train\", \"val\"]):\n",
    "        for img in image_data:\n",
    "            shutil.copy(\n",
    "                dataset_path / img[0],\n",
    "                split_dir / split / img[0],\n",
    "            )\n",
    "\n",
    "            txt_path = split_dir / split / img[0].replace(\".png\", \".txt\").replace('image', 'label')\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                for polygon in img[1]:\n",
    "                    polygon_parsed = polygon[1].split(\";\")\n",
    "                    for i, point in enumerate(polygon_parsed):\n",
    "                        x, y = point.split(\",\")\n",
    "                        x = float(x) / img[2][0]\n",
    "                        y = float(y) / img[2][1]\n",
    "                        polygon_parsed[i] = f\"{x} {y}\"\n",
    "                    polygon_parsed = \" \".join(polygon_parsed)\n",
    "                    f.write(f\"{polygon[0]} {polygon_parsed}\\n\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(\n",
    "    imgs,\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "save_path = Path(dataset_path / \"80-20_Split\")\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "(save_path / \"train\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "(save_path / \"train\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "(save_path / \"val\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "(save_path / \"val\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_yaml = save_path / f\"dataset.yaml\"\n",
    "\n",
    "with open(dataset_yaml, \"w\") as ds_y:\n",
    "\n",
    "    yaml.safe_dump(\n",
    "        {\n",
    "            \"path\": save_path.resolve().as_posix(),\n",
    "            \"train\": \"./train\",\n",
    "            \"val\": \"./val\",\n",
    "            \"names\": idx_to_class,\n",
    "        },\n",
    "        ds_y,\n",
    "    )\n",
    "\n",
    "for image_data, split in zip([train_data, val_data], [\"train\", \"val\"]):\n",
    "    for img in image_data:\n",
    "        shutil.copy(\n",
    "            dataset_path / img[0],\n",
    "            save_path / split / img[0],\n",
    "        )\n",
    "\n",
    "        txt_path = save_path / split / img[0].replace(\".png\", \".txt\").replace('image', 'label')\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            for polygon in img[1]:\n",
    "                polygon_parsed = polygon[1].split(\";\")\n",
    "                for i, point in enumerate(polygon_parsed):\n",
    "                    x, y = point.split(\",\")\n",
    "                    x = float(x) / img[2][0]\n",
    "                    y = float(y) / img[2][1]\n",
    "                    polygon_parsed[i] = f\"{x} {y}\"\n",
    "                polygon_parsed = \" \".join(polygon_parsed)\n",
    "                f.write(f\"{polygon[0]} {polygon_parsed}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
